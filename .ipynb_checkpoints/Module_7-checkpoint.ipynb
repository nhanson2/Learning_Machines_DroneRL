{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages\n",
    "import math\n",
    "import time\n",
    "import signal\n",
    "import typing\n",
    "import warnings\n",
    "import cv2, PIL\n",
    "import threading\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cv2 import aruco\n",
    "import matplotlib as mpl\n",
    "from djitellopy import Tello\n",
    "import ipywidgets as widgets\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "%matplotlib nbagg\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e741792",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create buttons for controlling the drone\n",
    "dir_items = [\n",
    "    widgets.Button(\n",
    "        description='left',\n",
    "        button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='arrow-left' # (FontAwesome names without the `fa-` prefix)\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='forward',\n",
    "        button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='arrow-up' # (FontAwesome names without the `fa-` prefix)\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='backward',\n",
    "        button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='arrow-down' # (FontAwesome names without the `fa-` prefix)\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='right',\n",
    "        button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='arrow-right' # (FontAwesome names without the `fa-` prefix)\n",
    "    )]\n",
    "rot_items = [\n",
    "    widgets.Button(\n",
    "        description='rotate left',\n",
    "        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='rotate-left' # (FontAwesome names without the `fa-` prefix)\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='rotate right',\n",
    "        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='rotate-right' # (FontAwesome names without the `fa-` prefix)\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='stop',\n",
    "        button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='stop' # (FontAwesome names without the `fa-` prefix)\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='land',\n",
    "        button_style='warning', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        icon='caret-down' # (FontAwesome names without the `fa-` prefix)\n",
    "    )  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let's first define some actions\n",
    "\n",
    "Drone should be able to\n",
    "* Rotate left\n",
    "* Rotate right\n",
    "* Move left\n",
    "* Move right\n",
    "* Move forward\n",
    "* Move backwards\n",
    "\n",
    "6 possible actions, okay, how big can we make our state space?\n",
    "\n",
    "state space\n",
    "'''\n",
    "### GLOBAL VARIABLES ###\n",
    "camera_matrix = np.array([[230.912545, 0.000000, 120.790180],\n",
    "[0.000000, 230.691836, 158.098598],\n",
    "[0.000000, 0.000000, 1.000000]])\n",
    "\n",
    "distortion_coeff = np.array([0.278917, -0.485155, 0.002496, 0.004631, 0.000000])\n",
    "### Create Aruco tag detection framework\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_APRILTAG_36h11)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "\n",
    "# Image size parameters\n",
    "MARKER_SIZE = 0.2 # Marker size is 200 mm\n",
    "IMAGE_W = 240 # This corresponds to __ direction\n",
    "IMAGE_H = 320 # This corresponds to __ direction\n",
    "GRID_N = 10 # Discretization for image\n",
    "ANGLE_N = 4 # Discretization for rotation\n",
    "\n",
    "# RL Parameters - These might need to be tuned later on\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.95\n",
    "NEW_ACTION = False\n",
    "USE_ACTION = 6 # Default to holding in postion\n",
    "NUM_ACTIONS = 6\n",
    "WAIT_INPUT = False\n",
    "\n",
    "def state_to_grid_ref(state: np.array) -> np.ndarray:\n",
    "    '''\n",
    "    Take the current state of the tag, and find what indices we should use to update\n",
    "    \n",
    "    param:\n",
    "        state (np.array): x,y,theta\n",
    "    returns:\n",
    "        (np.array): Bin the current position belongs in\n",
    "    '''\n",
    "    # Discretize the x-y\n",
    "    #print(state)\n",
    "    x_grid = int(np.clip(state[0] // (IMAGE_W/GRID_N), 0, GRID_N))\n",
    "    y_grid = int(np.clip(state[1] // (IMAGE_H/GRID_N), 0, GRID_N))\n",
    "    theta_raw = state[2]\n",
    "    # Rotation bins: [[45,135],[135,225],[225,315],[315,45]]\n",
    "    if theta_raw > -15 and theta_raw < 15: # Forward direction\n",
    "        theta_grid = 0\n",
    "    elif theta_raw <= -15 and theta_raw >= -135: # Left direction\n",
    "        theta_grid = 1\n",
    "    elif theta_raw > 135 or theta_raw < -135: # Down direction\n",
    "        theta_grid = 2\n",
    "    elif theta_raw >= 15 and theta_raw <= 135: # Right direction\n",
    "        theta_grid = 3\n",
    "#     print(f'Converted grid reference: {np.array([x_grid, y_grid, theta_grid])}')\n",
    "    return np.array([x_grid, y_grid, theta_grid])\n",
    "\n",
    "def create_q_table(x_y_space: int, rotation_increments: int, num_actions: int):\n",
    "    '''\n",
    "    Create the lookup value for the Q-value grid\n",
    "    \n",
    "    param:\n",
    "        x_y_space (int): Number of discrete grid cells to use for the x-y state space\n",
    "        rotation_increments (int): Number of rotation discretizations (360/n)\n",
    "        num_actions (int): Length of total selectable actions\n",
    "    \n",
    "    returns:\n",
    "        (np.ndarray) - 4-D array representing the Q-values for each action\n",
    "    '''\n",
    "    # This table is a 4-D array, where each x,y,z-rotation\n",
    "    # Intialize to the minimum value\n",
    "    return np.zeros((x_y_space, x_y_space, rotation_increments, num_actions))\n",
    "\n",
    "def create_policy_table(q_table: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Given a Q-table at the end of the training cycle, create a simple policy that maps actions from the value of being\n",
    "    in a state e.g.\n",
    "    \n",
    "    param:\n",
    "        q_table (np.ndarray): 4-D array representing the Q-values for each action\n",
    "    \n",
    "    returns:\n",
    "        (np.ndarray): 3-D array representing the best action to choose given the current x,y,theta position\n",
    "    '''\n",
    "    # Create the best action, by estimating the value of being in a particular state\n",
    "    return np.argmax(q_table, axis=3)\n",
    "\n",
    "\n",
    "def get_action_from_policy(policy: np.ndarray, state) -> np.ndarray:\n",
    "    '''\n",
    "    Given a Q-table at the end of the training cycle, create a simple policy that maps actions from the value of being\n",
    "    in a state e.g.\n",
    "    \n",
    "    param:\n",
    "        policy (np.ndarray): Action table for state\n",
    "        state (np.array): x,y,theta of drone\n",
    "    returns:\n",
    "        (int): Action to execute on drone\n",
    "    '''\n",
    "    # State\n",
    "    state_idx = state_to_grid_ref(state)\n",
    "    # Prevent us from exploring only a single option\n",
    "    all_actions = Q_TABLE[state_idx[0],state_idx[1],state_idx[2],:]\n",
    "    tied_actions = np.where(all_actions == np.max(all_actions))[0]\n",
    "    return np.random.choice(tied_actions)\n",
    "\n",
    "def setup_drone():\n",
    "    '''\n",
    "    Connects to the Tello drone\n",
    "    \n",
    "    returns:\n",
    "        (Tello) Connected instance of the DJI Tello drone\n",
    "    '''\n",
    "    try:\n",
    "        # Create tello instance\n",
    "        tello = Tello()\n",
    "        # Connect to the drone\n",
    "        tello.connect()\n",
    "        # Start streaming data\n",
    "        tello.streamon()\n",
    "        return tello\n",
    "    except Exception as e:\n",
    "        print(f'Oops! an error occured: {str(e)}')\n",
    "        print(traceback.print_exc())\n",
    "        \n",
    "def process_image(img: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Pre-process image by removing byte junk, rotating, and sharpening\n",
    "    \n",
    "    param:\n",
    "        img (np.ndarray): 2-D image array representing the pixel intensities\n",
    "        \n",
    "    returns:\n",
    "        (np.ndarray): Cleaned image\n",
    "    \n",
    "    '''\n",
    "    # Remove garbage bytes from framebuffer\n",
    "    img = img[:240]\n",
    "    # Rotate image into the correct orientation\n",
    "    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    # Try to sharpen the image to help with aruco tag detection\n",
    "    #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    #img = cv2.filter2D(img, -1, kernel)\n",
    "    return img\n",
    "\n",
    "def detect_aruco_and_pose(img: np.ndarray) -> np.array:\n",
    "    '''\n",
    "    Detect ArUco tags in an image using the April Tag library\n",
    "    \n",
    "    param:\n",
    "        img (np.ndarray): Input downward facing camera image\n",
    "    \n",
    "    returns:\n",
    "        (np.ndarray): Calculated object pose (x,y,theta)\n",
    "    '''\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(img, aruco_dict, parameters=parameters)\n",
    "    if len(corners) > 0:\n",
    "        frame_markers = aruco.drawDetectedMarkers(img.copy(), corners, ids)\n",
    "        # Given the image, let's estimate our pose\n",
    "        pose = pose_estimation(corners, ids, img.copy())\n",
    "        # font\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        # org\n",
    "        org = (20, 20)\n",
    "        # fontScale\n",
    "        fontScale = 0.5\n",
    "        # Blue color in BGR\n",
    "        color = (255, 0, 0)\n",
    "        # Line thickness of 2 px\n",
    "        thickness = 2\n",
    "        # Using cv2.putText() method\n",
    "        frame_markers = cv2.putText(frame_markers, f'x:{int(pose[0])} y:{int(pose[1])} t:{int(pose[2])}', org, font, \n",
    "                           fontScale, color, thickness, cv2.LINE_AA)\n",
    "        # Draw center dot\n",
    "        frame_markers = cv2.circle(frame_markers, (int(pose[0]), int(pose[1])), 10, (0,0,255), -1)\n",
    "        # Draw the grid references\n",
    "        pose_ref = state_to_grid_ref(pose)\n",
    "        frame_markers = cv2.putText(frame_markers, f'Grid Ref: {pose_ref}', (0,320), font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('Aruco Tags', frame_markers)\n",
    "        # cv2.imwrite('./img/last.png', frame_markers)\n",
    "        return pose\n",
    "    else:\n",
    "        # print('NO TAG DETECTED! PLEASE MOVE THE DRONE IN SIGHT OF THE TAG AND CONTINUE')\n",
    "        return np.array([])\n",
    "    \n",
    "def isRotationMatrix(R: np.ndarray) -> bool:\n",
    "    '''\n",
    "    Checks whether a rotation matrix is valid\n",
    "    \n",
    "    param:\n",
    "        R (np.ndarray): Rotation matrix\n",
    "    returns:\n",
    "        (bool): Status as valid rotation matrix\n",
    "    '''\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    " \n",
    "# Calculates rotation matrix to euler angles\n",
    "# The result is the same as MATLAB except the order\n",
    "# of the euler angles ( x and z are swapped ).\n",
    "def rotationMatrixToEulerAngles(R: np.ndarray) -> np.array:\n",
    "    '''\n",
    "    Calculates rotation matrix to euler angles\n",
    "    The result is the same as MATLAB except the order\n",
    "    of the euler angles ( x and z are swapped ).\n",
    "    \n",
    "    param:\n",
    "        R (np.ndarray): Rotation matrix\n",
    "    returns:\n",
    "        (np.array): Roll, pitch, yaw\n",
    "    '''\n",
    " \n",
    "    assert(isRotationMatrix(R))\n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def extract_rotation(rvect: np.ndarray) -> float:\n",
    "    '''\n",
    "    Convert Rodrigues rotation representation to Euler angle for ease of use\n",
    "    \n",
    "    param:\n",
    "        rvect (np.ndarray): Representation of rotation in angle-axis notation\n",
    "    returns:\n",
    "        (float): Euler angle of rotation around the z-axis\n",
    "    '''\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rvect)\n",
    "    # Get just the z-axis rotation value\n",
    "    return np.degrees(rotationMatrixToEulerAngles(rotation_matrix)[2])\n",
    "\n",
    "def pose_estimation(corners: List, ids: List, frame: np.ndarray) -> None:\n",
    "    # If markers are detected\n",
    "    if len(corners) > 0:\n",
    "        for i in range(0, len(ids)):\n",
    "            # Estimate pose of each marker and return the values rvec and tvec---(different from those of camera coefficients)\n",
    "            \n",
    "            rotation, translation, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], MARKER_SIZE, camera_matrix,\n",
    "                                                                       distortion_coeff)\n",
    "            # Draw a square around the markers\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners) \n",
    "            # Draw Axis\n",
    "            frame = cv2.drawFrameAxes(frame, camera_matrix, distortion_coeff, rotation, translation, 0.01)  \n",
    "            # Calculate the position IN the image here\n",
    "            x, y = [corners[0][0][:, 0].mean()], [corners[0][0][:, 1].mean()]\n",
    "            theta = extract_rotation(rotation)\n",
    "            return np.array([x[0],y[0],theta])\n",
    "    else:\n",
    "        return np.array([])\n",
    "    \n",
    "\n",
    "def update_q_table(state: np.array, action: int, state_prime: np.array) -> None:\n",
    "    '''\n",
    "    Update value of action in table using the Q-function\n",
    "    \n",
    "    param:\n",
    "        state (np.array): Current state discretization\n",
    "        action (int): Numeric value indicating what we should do\n",
    "        state_prime (np.array): Next predicted state\n",
    "    return:\n",
    "        None\n",
    "    '''\n",
    "    # Q(s,a) = Q(s,a) + alpha * [R(s,a)] + gamma * max Q(s',a') - Q(s,a)]\n",
    "    global Q_TABLE\n",
    "    state_idx = state_to_grid_ref(state)\n",
    "    state_prime_idx = state_to_grid_ref(state_prime)\n",
    "    Q_TABLE[(*state_idx,action)] += ALPHA * (reward(state,action) + GAMMA * np.max(Q_TABLE[state_prime_idx]) - Q_TABLE[(*state_idx,action)])\n",
    "\n",
    "def reward(state: np.array, action: int) -> float:\n",
    "    '''\n",
    "    Calculate the exected reward of being in a state and taking an action\n",
    "    \n",
    "    param:\n",
    "        state (np.array): Current state of the drone\n",
    "        action (int): Encoded action to execute\n",
    "    returns:\n",
    "        (float): Calculated reward for occupying the current state\n",
    "    '''\n",
    "    # Okay spit balling this reward function - the reward here should be a function of the offset angle\n",
    "    # of the drone. e.g. given 0 is the target, are we between +/- 45, or are we completely turned around\n",
    "    # secondly the reward should be a penalty for the distnace\n",
    "    # basically, if the drone is not in the correct angle, it should rotate to face the heading vector\n",
    "    # THEN the function should penalize being outside of center of the image by some amount\n",
    "    goal_state = np.array([IMAGE_W/2, IMAGE_H/2])\n",
    "    distance = np.linalg.norm(state[:2] - goal_state)\n",
    "    print(f'Distance to goal: {distance}')\n",
    "    # See how close we are on the angle\n",
    "    grid_ref = state_to_grid_ref(state)\n",
    "    # Drone is not in the forward position, we should rotate to face the target direction\n",
    "    # If the distance is short, we are within some close portion of the goal\n",
    "    if distance > 50:\n",
    "        return 0 # Slightly prioritize rotating, but penalize offset distance\n",
    "    else:\n",
    "        return 1 # Huzzah! We are in a good enough state\n",
    "    # Drone is not in the forward position\n",
    "    if grid_ref[2] != 0:\n",
    "        return -0.1\n",
    "    \n",
    "    \n",
    "def stop_action() -> None:\n",
    "    '''\n",
    "    Send a blank action to keep the drone from drifting in a certain direction\n",
    "    '''\n",
    "    for _ in range(10):\n",
    "        tello.send_rc_control(0, 0, 0, 0)\n",
    "        \n",
    "def next_step(state: np.array, action: int) -> np.array:\n",
    "    '''\n",
    "    Given the current state and a selected action, estimate the location of the\n",
    "    fiducial marker in the next time step\n",
    "    \n",
    "    e.g. (state) + velocity command * timestep ~= new state\n",
    "    \n",
    "    The tello has imperfect vehicle dynamics, so this allows us to make a reasoned\n",
    "    estimate using the Bellman equation\n",
    "    \n",
    "    [0] Rotate left\n",
    "    [1] Rotate right\n",
    "    [2] Move left\n",
    "    [3] Move right\n",
    "    [4] Move forward\n",
    "    [5] Move backwards\n",
    "    [6] STOP\n",
    "    \n",
    "    NOTE: THESE TRANSITION STEPS ARE DEPENDENT ON ALTITUDE, WHICH SHOULD REMAIN FIXED!\n",
    "    \n",
    "    TARGET HEIGHT = 1 meter above the ground\n",
    "    \n",
    "    param:\n",
    "        state (np.array): x,y,theta position of the drone\n",
    "        action (int): Encoded action to execute\n",
    "    returns:\n",
    "        (np.array): New predicted state\n",
    "    '''\n",
    "    next_state = state\n",
    "    new_theta = state[2]\n",
    "    if action == 0: # Rotate left\n",
    "        if state[2] < -175: # This is about where the range of the drone will clip\n",
    "            new_theta = state[2] - 5\n",
    "        else:\n",
    "            next_theta = 180 - abs(state[2] - 5 + 180) # This should be right\n",
    "    elif action == 1: # Rotate right, increase by 5\n",
    "        if state[2] < 175:\n",
    "            new_theta = state[2] + 5\n",
    "        else:\n",
    "            next_theta = -180 + abs(state[2] - 5 - 180) # This should be right\n",
    "    elif action == 2: # Move left, target will shift to right\n",
    "        next_state[0] = state[0] + 24\n",
    "    elif action == 3: # Move right in the world, target will shift to left\n",
    "        next_state[0] = state[0] - 24\n",
    "    elif action == 4: # Move forwards, target will shift down\n",
    "        next_state[1] = state[1] + 30\n",
    "    elif action == 5: # Move backwards, target will shift up\n",
    "        next_state[1] = state[1] - 30\n",
    "    elif action == 6: # Stay\n",
    "        pass\n",
    "    \n",
    "    # Perform logic to double check our state\n",
    "    new_x = np.clip(next_state[0], 0, IMAGE_W)\n",
    "    new_y = np.clip(next_state[1], 0, IMAGE_H)    \n",
    "    return np.array([new_x, new_y, new_theta])\n",
    "\n",
    "    \n",
    "def take_action(action: int) -> None:\n",
    "    '''\n",
    "    Take action that advances our state\n",
    "    \n",
    "    param:\n",
    "        action (int): Encoded action to execute\n",
    "    '''\n",
    "    SPEED = 20 # This value is hard-coded and can be adjusted as need be\n",
    "    lr_vel = 0\n",
    "    fb_vel = 0\n",
    "    ud_vel = 0\n",
    "    yaw = 0\n",
    "    if action == 0:\n",
    "        yaw = -SPEED # Rotate clockwise\n",
    "    elif action == 1:\n",
    "        yaw = SPEED # Rotate counterclockwise\n",
    "    elif action == 2:\n",
    "        lr_vel = -SPEED # Left\n",
    "    elif action == 3:\n",
    "        lr_vel = SPEED # Right\n",
    "    elif action == 4:\n",
    "        fb_vel = SPEED # Forward\n",
    "    elif action == 5:\n",
    "        fb_vel = -SPEED # Backwards\n",
    "    elif action == 6:\n",
    "        pass\n",
    "        \n",
    "    # Send our command to the drone\n",
    "    tello.send_rc_control(lr_vel, fb_vel, ud_vel, yaw)\n",
    "    time.sleep(0.1)\n",
    "    # Countermand the drone command to prevent the drone from drifting\n",
    "    stop_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e439c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create global tello drone instance\n",
    "tello = setup_drone()\n",
    "tello.takeoff()\n",
    "tello.set_video_direction(Tello.CAMERA_DOWNWARD)\n",
    "# Zero out any residual control inputs\n",
    "tello.send_rc_control(0, 0, 0, 0)\n",
    "\n",
    "# Create new value table\n",
    "Q_TABLE = create_q_table(GRID_N,ANGLE_N,NUM_ACTIONS)\n",
    "# Create new policy\n",
    "POLICY = create_policy_table(Q_TABLE)\n",
    "\n",
    "# Signal handler to remove dangling connections\n",
    "def shutdown_drone(sig, frame):\n",
    "    print('Gracefully shutting down connection...')\n",
    "    tello.land()\n",
    "    #### SAVE THE Q TABLE ###\n",
    "    np.save('./models/q_vals_temp.npy', Q_TABLE)\n",
    "    ### SAVE THE POLICY\n",
    "    np.save('./models/policy_temp.npy', POLICY)\n",
    "\n",
    "# Register the shutdown command\n",
    "signal.signal(signal.SIGINT, shutdown_drone)\n",
    "\n",
    "# Define callback function for button presses\n",
    "def on_button_clicked(b):\n",
    "    print(b.description)\n",
    "    if b.description == 'land':\n",
    "        shutdown_drone(None,None)\n",
    "        return\n",
    "    lookup = {\n",
    "        'rotate left': 0,\n",
    "        'rotate right': 1,\n",
    "        'left': 2,\n",
    "        'right': 3,\n",
    "        'forward': 4,\n",
    "        'backward': 5,\n",
    "        'stop': 6,\n",
    "    }\n",
    "    global USE_ACTION\n",
    "    USE_ACTION = lookup[b.description]\n",
    "    global WAIT_INPUT\n",
    "    WAIT_INPUT = False\n",
    "\n",
    "# Assign the callback function for each of the buttons\n",
    "for button in dir_items:\n",
    "    button.on_click(on_button_clicked)\n",
    "for button in rot_items:\n",
    "    button.on_click(on_button_clicked)\n",
    "\n",
    "# Main execution loop\n",
    "def train_e_greedy():\n",
    "    POLICY = create_policy_table(Q_TABLE)\n",
    "    while True:\n",
    "        # grab current image from the drone\n",
    "        img = tello.get_frame_read().frame\n",
    "        img = process_image(img)\n",
    "        # print(img.shape)\n",
    "        cv2.imshow('Tello Vid', img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        # Detect aruco tag and calculate its current pose (x,y,theta)\n",
    "        # Allow user to take an action - this would normally be an epsilon greedy step\n",
    "        state = detect_aruco_and_pose(img)\n",
    "        # Estimate our current pose\n",
    "        if len(state) > 0:\n",
    "            if np.random.rand() > 0.90:\n",
    "                action = np.random.choice(range(6))\n",
    "            else:\n",
    "                action = get_action_from_policy(POLICY, state)\n",
    "            print(f'State: {state} Action: {action}')\n",
    "            # Given an action and the current state, predict where the drone will end up next\n",
    "            state_prime = next_step(state, action)\n",
    "            # Update the Q table\n",
    "            update_q_table(state, action, state_prime)\n",
    "            # apply the action\n",
    "            take_action(action)\n",
    "            # update the policy\n",
    "            POLICY = create_policy_table(Q_TABLE)\n",
    "        time.sleep(0.1)\n",
    "    tello.land()\n",
    "        \n",
    "def train_human_in_the_loop():\n",
    "    POLICY = create_policy_table(Q_TABLE)\n",
    "    while True:\n",
    "        # grab current image from the drone\n",
    "        img = tello.get_frame_read().frame\n",
    "        img = process_image(img)\n",
    "        # print(img.shape)\n",
    "        cv2.imshow('Tello Vid', img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        # Detect aruco tag and calculate its current pose (x,y,theta)\n",
    "        # Allow user to take an action - this would normally be an epsilon greedy step\n",
    "        state = detect_aruco_and_pose(img)\n",
    "        # Estimate our current pose\n",
    "        if len(state) > 0:\n",
    "            random_number = np.random.rand()\n",
    "            if random_number > 0.90:\n",
    "                # 10% of the time, try a random action\n",
    "                action = np.random.choice(range(6)) # Take a random action\n",
    "            elif random_number > 0.50:\n",
    "                # 40% of the time, we ask the user for the correct input\n",
    "                global WAIT_INPUT\n",
    "                WAIT_INPUT = True\n",
    "                display(widgets.VBox([widgets.HBox(dir_items), widgets.HBox(rot_items)]))\n",
    "                while WAIT_INPUT:\n",
    "                    action = USE_ACTION\n",
    "                    time.sleep(0.1)\n",
    "            else:\n",
    "                # 50% of the time, we take an action from the policy\n",
    "                action = get_action_from_policy(POLICY, state)\n",
    "            print(f'State: {state} Action: {action}')\n",
    "            # Given an action and the current state, predict where the drone will end up next\n",
    "            state_prime = next_step(state, action)\n",
    "            # Update the Q table\n",
    "            update_q_table(state, action, state_prime)\n",
    "            # apply the action\n",
    "            take_action(action)\n",
    "            # update the policy\n",
    "            POLICY = create_policy_table(Q_TABLE)\n",
    "        time.sleep(0.1)\n",
    "    tello.land()\n",
    "        \n",
    "def evaluate_policy(POLICY: np.ndarray) -> None:\n",
    "    '''\n",
    "    Evaluate a saved policy\n",
    "    '''\n",
    "    while True:\n",
    "        # grab current image from the drone\n",
    "        img = tello.get_frame_read().frame\n",
    "        img = process_image(img)\n",
    "        # print(img.shape)\n",
    "        cv2.imshow('Tello Vid', img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        # Detect aruco tag and calculate its current pose (x,y,theta)\n",
    "        state = detect_aruco_and_pose(img)\n",
    "        # Estimate our current pose\n",
    "        if len(state) > 0:\n",
    "            action = get_action_from_policy(POLICY, state)\n",
    "            print(f'State: {state} Action: {action}')\n",
    "            # apply the action\n",
    "            take_action(action)\n",
    "            # update the policy\n",
    "            POLICY = create_policy_table(Q_TABLE)\n",
    "        time.sleep(0.1)\n",
    "    tello.land()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39721bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "#### SAVE THE Q TABLE ###\n",
    "np.save('./models/q_vals.npy', Q_TABLE)\n",
    "### SAVE THE POLICY\n",
    "np.save('./models/policy.npy', POLICY)\n",
    "tello.land()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
